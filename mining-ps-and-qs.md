# Mining Your Ps and Qs: Detection of Widespread Weak Keys in Network Devices
### Nadia Heninger (University of California, San Diego), Zakir Durumeric (The University of Michigan), et al.
### 21st USENIX Security Symposium (August 2012) ([Link](https://www.usenix.org/system/files/conference/usenixsecurity12/sec12-final228.pdf))

---

1. What are the paper's contributions and what did you like about the paper?  
The paper studies the expanse of vulnerable cryptographic keys and certificates, caused by faulty algorithm/RNG implementations, with emphasis on randomness. I liked that the paper also tried to show what I felt was an attacker's perspective in certain places - by showing comparisons of running certain computations on their machines vs with cloud compute, not just highlighting the ease of running it, but also the costs associated and time taken. I also liked the authors approach for efficient algorithms to cut down the time for GCD calculations over a huge pair set. Additionally, the researchers went a step forward to investigate the Linux, Windows and BSD RNGs to identify the root cause of poor entropy problems, rather than stopping at blaming the device manufacturers. Tangentially, the observation about the IBM devices generating keys using just a small set of prime factors is funny and embarassing for a company of that scale and reputation.

2. What are questionable parts of the paper and its major limitations? (E.g., methodology issues, detail omissions, presentation problems)  
What I felt a bit odd was that there were certain keys and certs that were being repeated because they were from the same organization or hosting provider. The authors considered this to not be a problem, but I don't feel that should be an acceptable practice. It might not be relevant to this paper, hence the author's assumptions, but it is worth a discussion on what should be the right approach in such cases.

3. What was unclear about the work, or what questions do you have?  
The paper is very expansive in covering all possible bases of the problem in hand, going multiple layers deep to find out root cause, so most of it is pretty clear. I did have a doubt on why the authors chose to look at Dropbear SSH server though (they do mention that it is a pretty well-known SSH server), but given that they found the exact vulnerability they needed, it begs the question of whether they went looking for a case for proving their hypothesis, or whether it is really the best option to look at.

4. Many of this paper’s findings were from analyzing data collected from an Internet-wide measurement. To what extent do you think we could have made these findings without Internet-wide data?  
The paper mentions that the EFF SSL Observatory dataset was the inspiration behind their scans itself, and without their scans, they'd have to have relied on the EFF dataset itself. But they also mention that their scan dataset was 67% larger than the EFF dataset, which is a significant size difference. I think doing their own scans enabled them to have more up-to-date and complete data. Also, the EFF dataset does not cover SSH. Having their own scans enabled them to look for a much wider range of devices, ensuring diversity in input data as well as improving the chances of getting collisions.

5. What are some approaches to remedying the issues identified in this paper? For each approach you suggest, discuss what challenges might impact the approach’s effectiveness in practice.  
There are many different facets to this paper, and multiple stakeholders are responsible for fixing the glaring holes each of their softwares have. The biggest one arguably is the RNG entropy problem, which can be solved right from the OS to the application level. Randomness isn't a solved problem, and there's still scope for research into better entropy sources, especially for headless and embedded devices. OS can prevent generating random numbers unless there's a sufficient level of entropy, or inform the applications about what's the entropy level at use when the random number was generated, giving control to applications to decide what to do with the generated data. But in practice, leaving this to the consumer application's judgement won't necessarily be enough, since the apps can simply choose to ignore the entropy level and use the random numbers due to ease. An app using their own entropy pool also might not be safe necessarily, given the observations in the paper. I feel another mitigation factor can be using unique "default" keys and certificates for each device (default in terms of what comes bundled with the device), to prevent collisions and reuse. In a lot of these solutions, the control effectively goes to the manufacturer's or software developer's hands, which might not necessarily think (out of incompetence or malice) these efforts to be useful enough to consider and implement, and sometimes, business priorities might take precedence over security, especially in the embedded devices world.
